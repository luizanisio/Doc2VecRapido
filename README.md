# Doc2VecRapido

==EM PREPARA√á√ÉO==

Componente python que simplifica o processo de cria√ß√£o de um modelo `Doc2Vec` [`Gensim 4.0.1`](https://radimrehurek.com/gensim/models/doc2vec.html) sem tatnos par√¢metros de configura√ß√£o como o [Doc2VecFacil](/Doc2VecFacil). Dicas de agrupamento de documentos similares, uso de `ElasticSearch` e `SingleStore`.
- se voc√™ n√£o sabe o que √© um modelo de similaridade, em resumo √© um algoritmo n√£o supervisionado para criar um modelo que transforma frases ou documentos em vetores matem√°ticos que podem ser comparados retornando um valor equivalente √† similaridade sem√¢ntica de documentos do mesmo contexto/dom√≠nio dos documentos usados no treinamento do modelo (doc2vec). Nesse cen√°rio a m√°quina 'aprende' o vocabul√°rio treinado e o contexto em que as palavras aparecem (word2vec), permitindo identificar a similaridade entre os termos, as frases e os documentos. O doc2vec amplia o treinamento do word2vec para frases ou documentos.
- alguns links para saber mais:
  - [`Paragraph Vector 2014`](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) - a origem do Doc2Vec
  - [`Gensim 4.0.1 Doc2Vec`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html) - documenta√ß√£o do framework
  - [`me Amilar 2018`](https://repositorio.idp.edu.br/handle/123456789/2635) - Disserta√ß√£o de Mestrado IDP - Doc2Vec em documentos jur√≠dicos
  - [`Representa√ß√£o Sem√¢ntica Vetorial`](https://sol.sbc.org.br/index.php/erigo/article/view/7125) - Artigo UFG
  - [`Word2Vec Explained`](https://www.youtube.com/watch?v=yFFp9RYpOb0) - v√≠deo no Youtube
  - [`Word Embedding Explained and Visualized`](https://www.youtube.com/watch?v=D-ekE-Wlcds) - v√≠deo no Youtube
  - [`ti-exame`](https://www.ti-enxame.com/pt/python/como-calcular-similaridade-de-sentenca-usando-o-modelo-word2vec-de-gensim-com-python/1045257495/) - Word2Vec
  - [`Tomas Mikolov paper`](https://arxiv.org/pdf/1301.3781.pdf) - mais um artigo sobre o Doc2Vec

- Com essa compara√ß√£o vetorial, √© poss√≠vel encontrar documentos semelhantes a um indicado ou [`agrupar documentos semelhantes`](https://github.com/luizanisio/Doc2VecFacil/blob/main/docs/agrupamento.md) entre si de uma lista de documentos (ser√° disponibilizado um c√≥digo espec√≠fico para o Doc2VecRapido). Pode-se armazenar os vetores no `SingleStore` ou `ElasticSearch` para permitir uma pesquisa vetorial r√°pida e combinada com metadados dos documentos, como nas dicas [aqui](#dicas).

- Em um recorte do espa√ßo vetorial criado pelo treinamento do modelo, pode-se perceber que documentos semelhantes ficam pr√≥ximos enquanto documentos diferentes ficam distantes entre si. Ent√£o agrupar ou buscar documentos semelhantes √© uma quest√£o de identificar a dist√¢ncia vetorial dos documentos ap√≥s o treinamento. Armazenando os vetores dos documentos no `ElasticSearch` ou `SingleStore`, essa tarefa √© simplificada, permitindo construir sistemas de busca sem√¢ntica com um esfor√ßo pequeno. Uma t√©cnica parecida pode ser usada para treinar e armazenar vetores de imagens para encontrar imagens semelhantes, mas isso fica para outro projeto. Segue aqui uma [`view`](docs/readme_dicas.md) e uma [`procedure`](docs/readme_dicas.md) para busca de similares e agrupamentos no SingleStore.

![exemplo recorte espa√ßo vetorial](./exemplos/img_recorte_espaco_vetorial.png?raw=true "Exemplo recorte de espa√ßo vetorial")

- O uso da similaridade permite tamb√©m um sistema sugerir r√≥tulos para documentos novos muito similares a documentos rotulados previamente ‚Äì como uma classifica√ß√£o r√°pida, desde que o r√≥tulo esteja relacionado ao conte√∫do geral do documento e n√£o a informa√ß√µes externas a ele. Rotula√ß√£o por informa√ß√µes muito espec√≠ficas do documento pode n√£o funcionar muito bem, pois detalhes do documento podem n√£o ser ressaltados na similaridade sem√¢ntica. 
- Outra possibilidade seria o sistema sugerir revis√£o de rotula√ß√£o/classifica√ß√£o quando dois documentos possuem similaridades muito altas, mas r√≥tulos distintos (como no exemplo do assunto A e B na figura abaixo), ou r√≥tulos iguais para similaridades muito baixas (n√£o √© necessariamente um erro, mas sugere-se confer√™ncia nesses casos). Ou o sistema pode auxiliar o usu√°rio a identificar r√≥tulos que precisam ser revistos, quando r√≥tulos diferentes s√£o encontrados para documentos muito semelhantes e os r√≥tulos poderiam ser unidos em um √∫nico r√≥tulo, por exemplo. Essas s√£o apenas algumas das possibilidades de uso da similaridade. 

![exemplo recorte espa√ßo vetorial e assuntos](./exemplos/img_agrupamento_assuntos.png?raw=true "Exemplo recorte de espa√ßo vetorial e assuntos")

> :bulb: Uma dica para conjuntos de documentos com pouca atualiza√ß√£o, √© fazer o c√°lculo da similaridade dos documentos e armazenar em um banco transacional qualquer para busca simples pelos metadados da similaridade. Por exemplo uma tabela com as colunas `seq_doc_1`, `seq_doc_2` e `sim` para todos os documentos que possuam similaridade acima de nn% a ser avaliado de acordo com o projeto. Depois basta fazer uma consulta simples para indicar documentos similares ao que o usu√°rio est√° acessando, por exemplo.

- O core desse componente √© o uso de um Tokenizador Inteligente que usa as configura√ß√µes dos arquivos contidos na pasta do modelo para tokenizar os arquivos de treinamento e os arquivos novos para compara√ß√£o no futuro (toda a configura√ß√£o do tokenizador √© opcional).
- Esse √© um reposit√≥rio de estudos. Analise, ajuste, corrija e use os c√≥digos como desejar.
> :thumbsup: <sub> Agradecimentos especiais ao Miguel Angelo Neto do Paran√° e ao me Amilar Martins por v√°rios feedbacks contribuindo para a corre√ß√£o de bugs e a melhoria da documenta√ß√£o.</sub><br>

> :warning: <sub>A quantidade de documentos treinados e de √©pocas de treinamento s√£o valores que dependem do objetivo e do tipo de texto de cada projeto.</sub><br>
> :warning: <sub>√â importante lembrar que ao atualizar o modelo com mais √©pocas de treinamento ou mais documentos, todos os vetores gerados anteriormente e guardados para compara√ß√£o no seu sistema devem ser atualizados. Uma dica √© criar uma tabela nova no SingleStore ou uma coluna nova no ElasticSearch e, ap√≥s a gera√ß√£o dos novos vetores, fazer a atualiza√ß√£o em bloco substituindo os vetores antigos pelos novos.</sub>

### As etapas de um treinamento s√£o simples:
1) reservar um volume de documentos que represente a sem√¢ntica que ser√° treinada. Ent√£o o primeiro passo √© extrair e separar em uma pasta os documentos que ser√£o usados no treinamento. √â interessante que sejam documentos ‚Äútexto puro‚Äù (n√£o ocerizados), mas n√£o impede que sejam usados documentos ocerizados na falta de documentos ‚Äútexto puro‚Äù. Com textos com muito ru√≠do, como em textos ocerizados, o vocabul√°rio "aprendido" pode n√£o ser t√£o eficiente.
2) preparar o ambiente python caso ainda n√£o tenha feito isso: [`anaconda`](https://www.anaconda.com/) + [`requirements`](./src/requirements.txt)
3) baixar os arquivos do [`projeto`](./src/) 
4) baixar um [`modelo`](./exemplos/) ou criar a sua estrutura de pastas
5) rodar o treinamento e explorar os recursos que o uso do espa√ßo vetorial permite
> :bulb: <sub> Nota: Esse √© o [tutorial oficial do gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#introducing-paragraph-vector), a ideia do componente √© simplificar a gera√ß√£o e uso do modelo treinado, mas n√£o h√° nada muito especial se comparado aos c√≥digos da documenta√ß√£o. </sub>

<hr>

## Voc√™ pode configurar alguns par√¢metros antes do treinamento para o `Doc2VecRapido`:
 - criar a pasta do modelo (por exemplo "meu_modelo") e criar o arquivo `config.json` com os seguintes par√¢metros.
  - `config.json = {"vector_size": 300, "strip_numeric":true, "stemmer":false, "min_count": 5 , "token_br": true}`
  - strip_numeric = remove n√∫meros (padr√£o true)
  - stemmer = utiliza o stemmer dos tokens (padr√£o false)
  - min_count = ocorr√™ncia m√≠nima do token no corpus para ser treinado (padr√£o 5)
  - token_br = cria o token #br para treinar simulando a quebra de par√°grafos (padr√£o true)
  - vector_size = n√∫mero de dimens√µes do vetor que ser√° treinado (padr√£o 300)

 - treinamento do modelo usando a estrutura de tokeniza√ß√£o criada 
   - `python util_doc2vec_rapido.py -pasta ./meu_modelo -treinar` -textos ./textos
   - o modelo ser√° gravado a cada 50 itera√ß√µes para continua√ß√£o do treino se ocorrer alguma interrup√ß√£o
> üí° <sub>Nota: para interromper o treino sem correr o risco corromper o modelo durante a grava√ß√£o, basta criar um arquivo `meu_modelo/parar.txt` na pasta do modelo que o treinamento ser√° interrompido ao final da itera√ß√£o em andamento.</sub>

 - carregando o modelo para compara√ß√£o
 ```python 
   from util_doc2vec_rapido import Doc2VecRapido
   dv = Doc2VecRapido(pasta_modelo = 'minha_pasta')
   texto_1 = 'esse √© um texto de teste para compara√ß√£o'
   texto_2 = 'esse outro texto de teste para uma nova compara√ß√£o'
   sim = 100*dv.similaridade(texto_1, texto_2)
   print(f'Similaridade texto 1 e 2: {sim:.2f}')       
```    
Resultado (a similaridade vai depender dos documentos usados no treinamento):
```
  Similaridade texto 1 e 2: 83.25%
```

## Dicas de uso: <a name="dicas">
- gravar os vetores, textos e metadados dos documentos no [`ElasticSearch`](https://www.elastic.co/pt/), e usar os recursos de pesquisas: More Like This, vetoriais e por proximidade de termos como disponibilizado no componente [`PesquisaElasticFacil`](https://github.com/luizanisio/PesquisaElasticFacil) ou criar sua pr√≥pria estrutura de dados com [`essas dicas`](https://github.com/luizanisio/PesquisaElasticFacil/blob/main/docs/ElasticQueries.md).
- gravar os vetores, textos e metadados no [`SingleStore`](https://www.singlestore.com/) e criar views de similaridade para consulta em tempo real dos documentos inseridos na base, incluindo filtros de metadados e textuais como nos exemplos dispon√≠veis aqui: [`dicas SingleStore`](./docs/readme_dicas.md).
